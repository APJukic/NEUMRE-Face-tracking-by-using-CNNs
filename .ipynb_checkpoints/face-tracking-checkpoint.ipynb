{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a81e0777",
   "metadata": {},
   "source": [
    "# Face tracking by using CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d66a26c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as fun\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import gc\n",
    "import torchvision.transforms as transforms\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f83b679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= Using device cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"= Using device {device}\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26635d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_block(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        \n",
    "        super(conv_block, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self, val):\n",
    "        return fun.relu(self.batchnorm(self.conv(val)))\n",
    "        \n",
    "\n",
    "class Inception_block(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out1x1, red3x3, out3x3, red5x5, out5x5, out1x1pool):\n",
    "        \n",
    "        super(Inception_block, self).__init__()\n",
    "        \n",
    "        self.branch1 = conv_block(in_channels, out1x1, kernel_size=1)\n",
    "        \n",
    "        self.branch2 = nn.Sequential(\n",
    "            conv_block(in_channels, red3x3, kernel_size=1),\n",
    "            conv_block(red3x3, out3x3, kernel_size=3, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.branch3 = nn.Sequential(\n",
    "            conv_block(in_channels, red5x5, kernel_size=1),\n",
    "            conv_block(red5x5, out5x5, kernel_size=5, padding=2)\n",
    "        )\n",
    "        \n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            conv_block(in_channels, out1x1pool, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, val):\n",
    "        return torch.cat([self.branch1(val), self.branch2(val), self.branch3(val), self.branch4(val)], 1)\n",
    "\n",
    "        \n",
    "#GoogLeNet\n",
    "class cnn_model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(cnn_model, self).__init__()\n",
    "\n",
    "        self.conv1 = conv_block(\n",
    "            in_channels=3,\n",
    "            out_channels=64,\n",
    "            kernel_size=7,\n",
    "            stride=2,\n",
    "            padding=3\n",
    "        )\n",
    "\n",
    "        self.conv2 = conv_block(\n",
    "            in_channels=64,\n",
    "            out_channels=192,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "\n",
    "        self.inception3a = Inception_block(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception3b = Inception_block(256, 128, 128, 192, 32, 96, 64)\n",
    "        \n",
    "        self.inception4a = Inception_block(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.inception4b = Inception_block(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception4c = Inception_block(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inception4d = Inception_block(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.inception4e = Inception_block(528, 256, 160, 320, 32, 128, 128)\n",
    "        \n",
    "        self.inception5a = Inception_block(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception5b = Inception_block(832, 384, 192, 384, 48, 128, 128)\n",
    "        \n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=1024,\n",
    "            out_features=4\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, val):\n",
    "        val = fun.relu(self.conv1(val))\n",
    "        val = fun.max_pool2d(val, kernel_size=3, stride=2)\n",
    "        val = fun.relu(self.conv2(val))\n",
    "        val = fun.max_pool2d(val, kernel_size=3, stride=2)\n",
    "        \n",
    "        val = self.inception3a(val)\n",
    "        val = self.inception3b(val)\n",
    "        val = fun.max_pool2d(val, kernel_size=3, stride=2)\n",
    "        \n",
    "        val = self.inception4a(val)\n",
    "        val = self.inception4b(val)\n",
    "        val = self.inception4c(val)\n",
    "        val = self.inception4d(val)\n",
    "        val = self.inception4e(val)\n",
    "        val = fun.max_pool2d(val, kernel_size=3, stride=2)\n",
    "\n",
    "        val = self.inception5a(val)\n",
    "        val = self.inception5b(val)\n",
    "        val = fun.avg_pool2d(val, kernel_size=6, stride=1)\n",
    "        \n",
    "        val = val.reshape(val.shape[0], -1)\n",
    "        val = fun.dropout(val, p=0.4, training=self.training)\n",
    "        val = self.fc1(val)\n",
    "        \n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "024e2937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cnn_model().to(device)\n",
    "model.load_state_dict(torch.load('./model_google.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "621d91f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"chess-nutz.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"chess-nutz.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dac8b305",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.4344, 0.4542, 0.4789]\n",
    "std = [0.2987, 0.3016, 0.3028]\n",
    "transform_norm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f62fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def videoToImages(pathIn, pathOut, resize_size=224):\n",
    "    count = 0\n",
    "    vidcap = cv2.VideoCapture(pathIn)\n",
    "    success,image = vidcap.read()\n",
    "    success = True\n",
    "    while success:\n",
    "        success,image = vidcap.read()\n",
    "        print(\"Frame \" + str(count) + \": \" + str(success))\n",
    "        if success:\n",
    "            image = cv2.resize(image, (resize_size, resize_size))\n",
    "            inputs = transform_norm(image)\n",
    "            #inputs = torch.Tensor(image.ravel())\n",
    "            inputs = inputs.view(1, 3, 224, 224)\n",
    "            predict = torch.squeeze(model(inputs.to(device)).detach().cpu()).tolist()\n",
    "        \n",
    "            image_pred = cv2.rectangle(image, (int(predict[0]), int(predict[1])),(int(predict[2]) + \n",
    "                                                                               int(predict[0]),\n",
    "                                              int(predict[3]) + int(predict[1])) , (255, 0, 0), 1)\n",
    "        \n",
    "            cv2.imwrite(pathOut + \"\\\\frame%d.jpg\" % count, image_pred)     # save frame as JPEG file\n",
    "            count = count + 1\n",
    "    return vidcap.get(cv2.CAP_PROP_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "621bad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagesToVideo(pathIn, pathOut, fps):\n",
    "    images = [img for img in os.listdir(pathIn) if img.endswith(\".jpg\")]\n",
    "    images = sorted(images, key=lambda x:int(x[5:-4]))\n",
    "    frame = cv2.imread(os.path.join(pathIn, images[0]))\n",
    "    height, width, layers = frame.shape\n",
    "\n",
    "    video = cv2.VideoWriter(pathOut, 0, fps, (width,height))\n",
    "\n",
    "    for image in images:\n",
    "        video.write(cv2.imread(os.path.join(pathIn, image)))\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4aabd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 0: True\n",
      "Frame 1: True\n",
      "Frame 2: True\n",
      "Frame 3: True\n",
      "Frame 4: True\n",
      "Frame 5: True\n",
      "Frame 6: True\n",
      "Frame 7: True\n",
      "Frame 8: True\n",
      "Frame 9: True\n",
      "Frame 10: True\n",
      "Frame 11: True\n",
      "Frame 12: True\n",
      "Frame 13: True\n",
      "Frame 14: True\n",
      "Frame 15: True\n",
      "Frame 16: True\n",
      "Frame 17: True\n",
      "Frame 18: True\n",
      "Frame 19: True\n",
      "Frame 20: True\n",
      "Frame 21: True\n",
      "Frame 22: True\n",
      "Frame 23: True\n",
      "Frame 24: True\n",
      "Frame 25: True\n",
      "Frame 26: True\n",
      "Frame 27: True\n",
      "Frame 28: True\n",
      "Frame 29: True\n",
      "Frame 30: True\n",
      "Frame 31: True\n",
      "Frame 32: True\n",
      "Frame 33: True\n",
      "Frame 34: True\n",
      "Frame 35: True\n",
      "Frame 36: True\n",
      "Frame 37: True\n",
      "Frame 38: True\n",
      "Frame 39: True\n",
      "Frame 40: True\n",
      "Frame 41: True\n",
      "Frame 42: True\n",
      "Frame 43: True\n",
      "Frame 44: True\n",
      "Frame 45: True\n",
      "Frame 46: True\n",
      "Frame 47: True\n",
      "Frame 48: True\n",
      "Frame 49: True\n",
      "Frame 50: True\n",
      "Frame 51: True\n",
      "Frame 52: True\n",
      "Frame 53: True\n",
      "Frame 54: True\n",
      "Frame 55: True\n",
      "Frame 56: True\n",
      "Frame 57: True\n",
      "Frame 58: True\n",
      "Frame 59: True\n",
      "Frame 60: True\n",
      "Frame 61: True\n",
      "Frame 62: True\n",
      "Frame 63: True\n",
      "Frame 64: True\n",
      "Frame 65: True\n",
      "Frame 66: True\n",
      "Frame 67: True\n",
      "Frame 68: True\n",
      "Frame 69: True\n",
      "Frame 70: True\n",
      "Frame 71: True\n",
      "Frame 72: True\n",
      "Frame 73: True\n",
      "Frame 74: True\n",
      "Frame 75: True\n",
      "Frame 76: True\n",
      "Frame 77: True\n",
      "Frame 78: True\n",
      "Frame 79: True\n",
      "Frame 80: True\n",
      "Frame 81: True\n",
      "Frame 82: True\n",
      "Frame 83: True\n",
      "Frame 84: True\n",
      "Frame 85: True\n",
      "Frame 86: True\n",
      "Frame 87: True\n",
      "Frame 88: True\n",
      "Frame 89: True\n",
      "Frame 90: True\n",
      "Frame 91: True\n",
      "Frame 92: True\n",
      "Frame 93: True\n",
      "Frame 94: True\n",
      "Frame 95: True\n",
      "Frame 96: True\n",
      "Frame 97: True\n",
      "Frame 98: True\n",
      "Frame 99: True\n",
      "Frame 100: True\n",
      "Frame 101: True\n",
      "Frame 102: True\n",
      "Frame 103: True\n",
      "Frame 104: True\n",
      "Frame 105: True\n",
      "Frame 106: True\n",
      "Frame 107: True\n",
      "Frame 108: True\n",
      "Frame 109: True\n",
      "Frame 110: True\n",
      "Frame 111: True\n",
      "Frame 112: True\n",
      "Frame 113: True\n",
      "Frame 114: True\n",
      "Frame 115: True\n",
      "Frame 116: True\n",
      "Frame 117: True\n",
      "Frame 118: True\n",
      "Frame 119: True\n",
      "Frame 120: True\n",
      "Frame 121: True\n",
      "Frame 122: True\n",
      "Frame 123: True\n",
      "Frame 124: True\n",
      "Frame 125: True\n",
      "Frame 126: True\n",
      "Frame 127: True\n",
      "Frame 128: True\n",
      "Frame 129: True\n",
      "Frame 130: True\n",
      "Frame 131: True\n",
      "Frame 132: True\n",
      "Frame 133: True\n",
      "Frame 134: True\n",
      "Frame 135: True\n",
      "Frame 136: True\n",
      "Frame 137: True\n",
      "Frame 138: True\n",
      "Frame 139: True\n",
      "Frame 140: True\n",
      "Frame 141: True\n",
      "Frame 142: True\n",
      "Frame 143: True\n",
      "Frame 144: True\n",
      "Frame 145: True\n",
      "Frame 146: True\n",
      "Frame 147: True\n",
      "Frame 148: True\n",
      "Frame 149: True\n",
      "Frame 150: True\n",
      "Frame 151: True\n",
      "Frame 152: True\n",
      "Frame 153: True\n",
      "Frame 154: True\n",
      "Frame 155: True\n",
      "Frame 156: True\n",
      "Frame 157: True\n",
      "Frame 158: True\n",
      "Frame 159: True\n",
      "Frame 160: True\n",
      "Frame 161: True\n",
      "Frame 162: True\n",
      "Frame 163: True\n",
      "Frame 164: True\n",
      "Frame 165: True\n",
      "Frame 166: True\n",
      "Frame 167: True\n",
      "Frame 168: True\n",
      "Frame 169: True\n",
      "Frame 170: True\n",
      "Frame 171: True\n",
      "Frame 172: True\n",
      "Frame 173: True\n",
      "Frame 174: True\n",
      "Frame 175: True\n",
      "Frame 176: True\n",
      "Frame 177: True\n",
      "Frame 178: True\n",
      "Frame 179: True\n",
      "Frame 180: True\n",
      "Frame 181: True\n",
      "Frame 182: True\n",
      "Frame 183: True\n",
      "Frame 184: True\n",
      "Frame 185: True\n",
      "Frame 186: True\n",
      "Frame 187: True\n",
      "Frame 188: True\n",
      "Frame 189: True\n",
      "Frame 190: True\n",
      "Frame 191: True\n",
      "Frame 192: True\n",
      "Frame 193: True\n",
      "Frame 194: True\n",
      "Frame 195: True\n",
      "Frame 196: True\n",
      "Frame 197: True\n",
      "Frame 198: True\n",
      "Frame 199: True\n",
      "Frame 200: True\n",
      "Frame 201: True\n",
      "Frame 202: True\n",
      "Frame 203: True\n",
      "Frame 204: True\n",
      "Frame 205: True\n",
      "Frame 206: True\n",
      "Frame 207: True\n",
      "Frame 208: True\n",
      "Frame 209: True\n",
      "Frame 210: True\n",
      "Frame 211: True\n",
      "Frame 212: True\n",
      "Frame 213: True\n",
      "Frame 214: True\n",
      "Frame 215: True\n",
      "Frame 216: True\n",
      "Frame 217: True\n",
      "Frame 218: True\n",
      "Frame 219: True\n",
      "Frame 220: True\n",
      "Frame 221: True\n",
      "Frame 222: True\n",
      "Frame 223: True\n",
      "Frame 224: True\n",
      "Frame 225: True\n",
      "Frame 226: True\n",
      "Frame 227: True\n",
      "Frame 228: True\n",
      "Frame 229: True\n",
      "Frame 230: True\n",
      "Frame 231: True\n",
      "Frame 232: True\n",
      "Frame 233: True\n",
      "Frame 234: True\n",
      "Frame 235: True\n",
      "Frame 236: True\n",
      "Frame 237: True\n",
      "Frame 238: True\n",
      "Frame 239: True\n",
      "Frame 240: True\n",
      "Frame 241: True\n",
      "Frame 242: True\n",
      "Frame 243: True\n",
      "Frame 244: True\n",
      "Frame 245: True\n",
      "Frame 246: True\n",
      "Frame 247: True\n",
      "Frame 248: True\n",
      "Frame 249: True\n",
      "Frame 250: True\n",
      "Frame 251: True\n",
      "Frame 252: True\n",
      "Frame 253: True\n",
      "Frame 254: True\n",
      "Frame 255: True\n",
      "Frame 256: True\n",
      "Frame 257: True\n",
      "Frame 258: True\n",
      "Frame 259: True\n",
      "Frame 260: True\n",
      "Frame 261: True\n",
      "Frame 262: True\n",
      "Frame 263: True\n",
      "Frame 264: True\n",
      "Frame 265: True\n",
      "Frame 266: True\n",
      "Frame 267: True\n",
      "Frame 268: True\n",
      "Frame 269: True\n",
      "Frame 270: True\n",
      "Frame 271: True\n",
      "Frame 272: True\n",
      "Frame 273: True\n",
      "Frame 274: True\n",
      "Frame 275: True\n",
      "Frame 276: True\n",
      "Frame 277: True\n",
      "Frame 278: True\n",
      "Frame 279: True\n",
      "Frame 280: True\n",
      "Frame 281: True\n",
      "Frame 282: True\n",
      "Frame 283: True\n",
      "Frame 284: True\n",
      "Frame 285: True\n",
      "Frame 286: True\n",
      "Frame 287: True\n",
      "Frame 288: True\n",
      "Frame 289: True\n",
      "Frame 290: True\n",
      "Frame 291: True\n",
      "Frame 292: True\n",
      "Frame 293: True\n",
      "Frame 294: True\n",
      "Frame 295: True\n",
      "Frame 296: True\n",
      "Frame 297: True\n",
      "Frame 298: True\n",
      "Frame 299: True\n",
      "Frame 300: True\n",
      "Frame 301: True\n",
      "Frame 302: True\n",
      "Frame 303: True\n",
      "Frame 304: True\n",
      "Frame 305: True\n",
      "Frame 306: True\n",
      "Frame 307: True\n",
      "Frame 308: True\n",
      "Frame 309: True\n",
      "Frame 310: True\n",
      "Frame 311: True\n",
      "Frame 312: True\n",
      "Frame 313: True\n",
      "Frame 314: True\n",
      "Frame 315: True\n",
      "Frame 316: True\n",
      "Frame 317: True\n",
      "Frame 318: True\n",
      "Frame 319: True\n",
      "Frame 320: True\n",
      "Frame 321: True\n",
      "Frame 322: True\n",
      "Frame 323: True\n",
      "Frame 324: True\n",
      "Frame 325: True\n",
      "Frame 326: True\n",
      "Frame 327: True\n",
      "Frame 328: True\n",
      "Frame 329: True\n",
      "Frame 330: True\n",
      "Frame 331: True\n",
      "Frame 332: True\n",
      "Frame 333: True\n",
      "Frame 334: True\n",
      "Frame 335: True\n",
      "Frame 336: True\n",
      "Frame 337: True\n",
      "Frame 338: True\n",
      "Frame 339: True\n",
      "Frame 340: True\n",
      "Frame 341: True\n",
      "Frame 342: True\n",
      "Frame 343: True\n",
      "Frame 344: True\n",
      "Frame 345: True\n",
      "Frame 346: True\n",
      "Frame 347: True\n",
      "Frame 348: True\n",
      "Frame 349: True\n",
      "Frame 350: True\n",
      "Frame 351: True\n",
      "Frame 352: True\n",
      "Frame 353: True\n",
      "Frame 354: True\n",
      "Frame 355: True\n",
      "Frame 356: True\n",
      "Frame 357: True\n",
      "Frame 358: True\n",
      "Frame 359: True\n",
      "Frame 360: True\n",
      "Frame 361: True\n",
      "Frame 362: True\n",
      "Frame 363: True\n",
      "Frame 364: True\n",
      "Frame 365: True\n",
      "Frame 366: True\n",
      "Frame 367: True\n",
      "Frame 368: True\n",
      "Frame 369: True\n",
      "Frame 370: True\n",
      "Frame 371: True\n",
      "Frame 372: True\n",
      "Frame 373: True\n",
      "Frame 374: True\n",
      "Frame 375: True\n",
      "Frame 376: True\n",
      "Frame 377: True\n",
      "Frame 378: True\n",
      "Frame 379: True\n",
      "Frame 380: True\n",
      "Frame 381: True\n",
      "Frame 382: True\n",
      "Frame 383: True\n",
      "Frame 384: True\n",
      "Frame 385: True\n",
      "Frame 386: True\n",
      "Frame 387: True\n",
      "Frame 388: True\n",
      "Frame 389: True\n",
      "Frame 390: True\n",
      "Frame 391: True\n",
      "Frame 392: True\n",
      "Frame 393: True\n",
      "Frame 394: True\n",
      "Frame 395: True\n",
      "Frame 396: True\n",
      "Frame 397: True\n",
      "Frame 398: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fps=videoToImages(\"chess-nutz.mp4\", \"video_frames\")\n",
    "fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "79d89835",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesToVideo(\"video_frames\", \"chess-nutz2.mp4\", fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c8e27cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"chess-nutz2.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"chess-nutz2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9256d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def streamToImages(pathOut, resize_size=224):\n",
    "    count = 0\n",
    "    vidcap = cv2.VideoCapture(0)\n",
    "    print()\n",
    "    success,image = vidcap.read()\n",
    "    success = True\n",
    "    while success:\n",
    "        success,image = vidcap.read()\n",
    "        #print(\"Frame \" + str(count) + \": \" + str(success))\n",
    "        \n",
    "        if success:\n",
    "            image = cv2.resize(image, (resize_size, resize_size))\n",
    "            inputs = transform_norm(image)\n",
    "            #inputs = torch.Tensor(image.ravel())\n",
    "            inputs = inputs.view(1, 3, 224, 224)\n",
    "            predict = torch.squeeze(model(inputs.to(device)).detach().cpu()).tolist()\n",
    "        \n",
    "            image_pred = cv2.rectangle(image, (int(predict[0]), int(predict[1])),(int(predict[2]) + \n",
    "                                                                               int(predict[0]),\n",
    "                                              int(predict[3]) + int(predict[1])) , (255, 0, 0), 1)\n",
    "        \n",
    "            #cv2.imwrite(pathOut + \"\\\\frame%d.jpg\" % count, image_pred)     # save frame as JPEG file\n",
    "            cv2.imshow('frame', image_pred)\n",
    "            count = count + 1\n",
    "            \n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "streamToImages(\"stream_frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a54be93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a6f4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
